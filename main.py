import subprocess
from pydub import AudioSegment

INPUT_FILE = "input.mp4"
TRACK1_FILE = "track1.wav"
TRACK2_FILE = "track2.wav"
NORMALIZED1 = "norm1.wav"
NORMALIZED2 = "norm2.wav"
FINAL_AUDIO = "final_audio.wav"
FINAL_VIDEO = "output.mp4"

# ã‚¹ãƒ†ãƒƒãƒ—1: éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ã‚’æŠ½å‡º
def extract_audio_tracks():
    subprocess.run(["ffmpeg", "-y", "-i", INPUT_FILE, "-map", "0:a:0", TRACK1_FILE])
    subprocess.run(["ffmpeg", "-y", "-i", INPUT_FILE, "-map", "0:a:1", TRACK2_FILE])

# ã‚¹ãƒ†ãƒƒãƒ—2: éŸ³é‡ã‚’æ­£è¦åŒ–ï¼ˆpydubã§ï¼‰
def normalize_audio(input_file, output_file):
    audio = AudioSegment.from_file(input_file, format="wav")
    change_in_dBFS = -20.0 - audio.dBFS
    normalized_audio = audio.apply_gain(change_in_dBFS)
    # normalized_audio.export(output_file, format="wav")

# ã‚¹ãƒ†ãƒƒãƒ—3: åŒæ™‚ã«ç„¡éŸ³ã«ãªã£ã¦ã„ã‚‹åŒºé–“ã‚’æ¤œå‡ºã—ã¦å‰Šé™¤ã—ã€ãƒ¢ãƒãƒ©ãƒ«ã§å‡ºåŠ›
def cut_silence(audio1_path, audio2_path, output_path):
    audio1 = AudioSegment.from_file(audio1_path, format="wav").set_channels(1)
    audio2 = AudioSegment.from_file(audio2_path, format="wav").set_channels(1)

    min_len = min(len(audio1), len(audio2))
    audio1 = audio1[:min_len]
    audio2 = audio2[:min_len]

    silence_thresh = -40  # ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆdBFSï¼‰
    chunk_size = 100      # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆmsï¼‰

    combined_chunks = []

    for i in range(0, min_len, chunk_size):
        chunk1 = audio1[i:i+chunk_size]
        chunk2 = audio2[i:i+chunk_size]

        if chunk1.dBFS > silence_thresh or chunk2.dBFS > silence_thresh:
            mixed_chunk = chunk1.overlay(chunk2)
            combined_chunks.append(mixed_chunk)

    if combined_chunks:
        result = sum(combined_chunks)
        result = result.set_channels(1)
        result.export(output_path, format="wav")
        print(f"âœ… ãƒ¢ãƒãƒ©ãƒ«éŸ³å£°ã¨ã—ã¦å‡ºåŠ›ã—ã¾ã—ãŸ: {output_path}")
    else:
        print("âš ï¸ å…¨ä½“ãŒç„¡éŸ³ã®ã‚ˆã†ã§ã™ã€‚éŸ³å£°ã¯å‡ºåŠ›ã•ã‚Œã¾ã›ã‚“ã€‚")

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’å–å¾—ï¼ˆç§’å˜ä½ï¼‰
def get_audio_duration_sec(audio_path):
    result = subprocess.run(
        ["ffprobe", "-v", "error", "-show_entries", "format=duration",
         "-of", "default=noprint_wrappers=1:nokey=1", audio_path],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    return float(result.stdout.strip())

# ã‚¹ãƒ†ãƒƒãƒ—4: æ˜ åƒã¨éŸ³å£°ã‚’ã€éŸ³å£°ã®é•·ã•ã«åˆã‚ã›ã¦åˆæˆ
def mux_audio_video(audio_path, output_path):
    audio_duration = get_audio_duration_sec(audio_path)
    subprocess.run([
        "ffmpeg", "-y",
        "-i", INPUT_FILE,
        "-i", audio_path,
        "-t", str(audio_duration),  # éŸ³å£°ã®é•·ã•ã«åˆã‚ã›ã¦æ˜ åƒã‚‚ãƒˆãƒªãƒ 
        "-map", "0:v:0", "-map", "1:a:0",
        "-c:v", "copy", "-c:a", "aac", "-ac", "1",
        output_path
    ])
    print(f"ğŸï¸ æ˜ åƒã¨éŸ³å£°ã‚’åˆæˆã—ã¾ã—ãŸ: {output_path}")

def main():
    extract_audio_tracks()
    normalize_audio(TRACK1_FILE, NORMALIZED1)
    normalize_audio(TRACK2_FILE, NORMALIZED2)
    cut_silence(NORMALIZED1, NORMALIZED2, FINAL_AUDIO)
    mux_audio_video(FINAL_AUDIO, FINAL_VIDEO)
    print("âœ… å®Œäº†ã—ã¾ã—ãŸã€‚å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:", FINAL_VIDEO)

if __name__ == "__main__":
    main()